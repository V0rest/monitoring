name: Deploy Monitoring

on:
  workflow_dispatch:
    inputs:
      destroy_infra:
        description: 'Destroy infrastructure'
        required: true
        default: 'false'

env:
  AWS_REGION: eu-west-1
  BUCKET: office-monitoring
  INSTANCE_DEPLOY_PATH: /etc/monitoring
  REPO_DEPLOYMENT_PATH: /local_deployment
  ANSIBLE_INVENTORY_FILE: inventory.aws_ec2.yml

jobs:
  terraform:
    name: "Deploy"
    runs-on: ubuntu-20.04
    environment: Prod

    steps:
      - name: Checkout
        uses: actions/checkout@v3
#
#      - name: Configure AWS credentials
#        uses: aws-actions/configure-aws-credentials@v1
#        with:
#          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID_VITECH_CLOUD }}
#          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY_VITECH_CLOUD }}
#          aws-region: ${{ env.AWS_REGION }}

      - name: "Setup - Build AWS Credentials"
        run: |
          mkdir -p ~/.aws
          echo "[default]" > ~/.aws/credentials
          echo "aws_access_key_id = ${{ secrets.AWS_ACCESS_KEY_ID_VITECH_CLOUD }}" >> ~/.aws/credentials
          echo "aws_secret_access_key = ${{ secrets.AWS_SECRET_ACCESS_KEY_VITECH_CLOUD }}" >> ~/.aws/credentials
          echo "[default]" > ~/.aws/config
          echo "region = ${{ secrets.AWS_DEFAULT_REGION }}" >> ~/.aws/config

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_wrapper: false

#      - name: Terraform Format
#        id: fmt
#        shell: bash
#        run: terraform fmt -check

      - name: Terraform Init
        id: init
        run: terraform init

      - name: Terraform Validate
        id: validate
        run: terraform validate -no-color

      - name: Terraform Plan
        id: plan
#        if: github.event_name == 'pull_request'
        run: terraform plan -no-color -input=false
        continue-on-error: true

      - name: Terraform Plan Status
        if: steps.plan.outcome == 'failure'
        run: exit 1

      - if: github.event.inputs.destroy_infra == 'false'
        name: Terraform Apply
        id: apply
        run: |
          terraform apply -auto-approve -input=false
          echo "::set-output name=instance_id::$(terraform output instance_id | tr -d "\"")"

      - if: github.event.inputs.destroy_infra == 'true'
        name: Terraform Destroy
        id: destroy
        run: |
          terraform destroy -auto-approve -input=false


#      - if: github.event.inputs.destroy_infra == 'false'
#        name: Checkout Code
#        uses: actions/checkout@v3


#      - if: github.event.inputs.destroy_infra == 'false'
#        name: Configure AWS credentials
#        uses: aws-actions/configure-aws-credentials@v1
#        with:
#          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID_VITECH_CLOUD }}
#          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY_VITECH_CLOUD }}
#          aws-region: ${{ env.AWS_REGION }}

      # This job as a targets uses EC2 tags to apply to specific instances
      #- if: github.event.inputs.destroy_infra == 'false'
      #  name: Sync-to-S3
      #  run: |
      #    aws s3 sync .${{ env.REPO_DEPLOYMENT_PATH }} s3://${{ env.BUCKET }}${{ env.REPO_DEPLOYMENT_PATH }}
      #    aws ssm send-command --document-name "AWS-RunShellScript" --document-version "1" --targets Key=tag:Name,Values=MLFlow_Registry_Server --parameters '{"workingDirectory":[""],"executionTimeout":["3600"],"commands":["aws s3 sync s3://${{ env.BUCKET }}${{ env.REPO_DEPLOYMENT_PATH }} ${{ env.INSTANCE_DEPLOY_PATH }}"]}' --timeout-seconds 600 --max-concurrency "50" --max-errors "0"  --output-s3-bucket-name "${{ env.BUCKET }}" --output-s3-key-prefix "ssm_logs/Sync-S3-EC2" --region ${{ env.AWS_REGION }}
      #    aws ssm send-command --document-name "AWS-RunShellScript" --document-version "1" --targets Key=tag:Name,Values=MLFlow_Registry_Server --parameters '{"workingDirectory":[""],"executionTimeout":["3600"],"commands":["sleep 5","sudo chmod a+x ${{ env.INSTANCE_DEPLOY_PATH }}/install.sh & bash ${{ env.INSTANCE_DEPLOY_PATH }}/install.sh"]}' --timeout-seconds 600 --max-concurrency "50" --max-errors "0"  --output-s3-bucket-name "${{ env.BUCKET }}" --output-s3-key-prefix "ssm_logs/Run install" --region ${{ env.AWS_REGION }}

      # This job as a targets uses output from terraform and set to ssm aws cli
      - if: github.event.inputs.destroy_infra == 'false'
        name: Sync-to-S3
        run: |
          INSTANCE_IDS=${{ steps.apply.outputs.instance_id }}
          aws s3 sync .${{ env.REPO_DEPLOYMENT_PATH }} s3://${{ env.BUCKET }}${{ env.REPO_DEPLOYMENT_PATH }}
          aws ssm send-command --document-name "AWS-RunShellScript" --document-version "1" --targets Key=InstanceIds,Values=$INSTANCE_IDS --parameters '{"workingDirectory":[""],"executionTimeout":["3600"],"commands":["aws s3 sync s3://${{ env.BUCKET }}${{ env.REPO_DEPLOYMENT_PATH }} ${{ env.INSTANCE_DEPLOY_PATH }}", "echo GRAFANA_ADMIN_PASSWORD=${{ secrets.GRAFANA_ADMIN_PASSWORD }} >> ${{ env.INSTANCE_DEPLOY_PATH }}/.env"]}' --timeout-seconds 600 --max-concurrency "50" --max-errors "0"  --output-s3-bucket-name "${{ env.BUCKET }}" --output-s3-key-prefix "ssm_logs/Sync-S3-EC2" --region ${{ env.AWS_REGION }}
          aws ssm send-command --document-name "AWS-RunShellScript" --document-version "1" --targets Key=InstanceIds,Values=$INSTANCE_IDS --parameters '{"workingDirectory":[""],"executionTimeout":["3600"],"commands":["sleep 5","sudo chmod a+x ${{ env.INSTANCE_DEPLOY_PATH }}/install.sh & bash ${{ env.INSTANCE_DEPLOY_PATH }}/install.sh"]}' --timeout-seconds 600 --max-concurrency "50" --max-errors "0"  --output-s3-bucket-name "${{ env.BUCKET }}" --output-s3-key-prefix "ssm_logs/Run install" --region ${{ env.AWS_REGION }}

#      - if: github.event.inputs.destroy_infra == 'false'
#        name: webfactory/ssh-agent
#        uses: webfactory/ssh-agent@v0.5.4
#        with:
#          ssh-private-key: ${{ secrets.ANSIBLE_SSH_KEY }}


      - if: github.event.inputs.destroy_infra == 'false'
        name: Write SSH Key to Disk
        shell: bash
        run: |
          echo "${{ secrets.ANSIBLE_SSH_KEY }}" > /home/runner/monitoring.pem
          chmod 400 /home/runner/monitoring.pem

      - if: github.event.inputs.destroy_infra == 'false'
        name: Cache Python Packages and Ansible
        id: cachestuff
        uses: actions/cache@v3.0.4
        with:
          path: |
            ~/.cache/
            ~/.ansible/
          key: python-ansible-cache



      - name: Install Dependencies
        if: |
         github.event.inputs.destroy_infra == 'false' ||
         (steps.cachestuff.outputs.cache-hit != 'true')
        shell: bash
        run: |
          pip3 install boto3 ansible
          ansible-galaxy collection install amazon.aws

      - if: github.event.inputs.destroy_infra == 'false'
        name: Validate Ansible Inventory
        run: |
          ansible-inventory --inventory ${{ env.ANSIBLE_INVENTORY_FILE }} --list -vvvv

      - if: github.event.inputs.destroy_infra == 'false'
        name: Run Ansible Playbook
        run: |
          ansible-playbook --inventory ${{ env.ANSIBLE_INVENTORY_FILE }} --private-key /home/runner/monitoring.pem ansible_playbook.yml
#/home/runner/monitoring.pem
#${{ env.SSH_AUTH_SOCK }}


      - name: Send custom JSON data to Slack workflow
        if: always()
        id: slack
        uses: slackapi/slack-github-action@v1.19.0
        with:
          # For posting a rich message using Block Kit
          payload: |
            {
              "text": "GitHub Action result: ${{ job.status }}\n${{ github.event.pull_request.html_url || github.event.head_commit.url }}"
    #          "blocks": [
    #            {
    #              "type": "section",
    #              "text": {
    #                "type": "mrkdwn",
    #                "text": "GitHub Action result: ${{ job.status }}\n${{ github.event.pull_request.html_url || github.event.head_commit.url }}"
    #              }
    #            }
    #          ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK
